{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBTa5Gw0X3VA6KlJqMMYa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IronmanBD/ML_AND_DL_Implementation_SCRATCH/blob/main/Covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zEUalduGH9p"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as transforms\n",
        "from skimage.util import montage\n",
        "import os\n",
        "import cv2 as cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt \n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "from torchvision.models import vgg19_bn\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "log_dir = \"~/logs\"\n",
        "writer = SummaryWriter(log_dir)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD6IpLEnGaNd",
        "outputId": "beb62df8-f5ec-4a56-b44e-a232c62073c5"
      },
      "source": [
        "!git clone https://github.com/UCSD-AI4H/COVID-CT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'COVID-CT' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYXAbU3XGoyD",
        "outputId": "f76b5f36-60d5-4547-edd7-ee49d7c1d3ff"
      },
      "source": [
        "%cd COVID-CT/Images-processed/\n",
        "!unzip CT_COVID.zip \n",
        "!unzip CT_NonCOVID.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/COVID-CT/Images-processed\n",
            "Archive:  CT_COVID.zip\n",
            "replace CT_COVID/2020.03.01.20029769-p21-73_1%1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_AgmWLCG0OL"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7_TWxvWG4HL"
      },
      "source": [
        "covid_files_path = 'Images-processed/CT_COVID'\n",
        "covid_files = [os.path.join(covid_files_path, x) for x in os.listdir(covid_files_path)]\n",
        "covid_images    =  [cv2.imread(x) for x in random.sample(covid_files, 10)]\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "columns = 5\n",
        "for i, image in enumerate(covid_images):\n",
        "    plt.subplot(len(covid_images) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpBdpkWFIW88"
      },
      "source": [
        "non_covid_files_path = 'Images-processed/CT_NonCOVID/'\n",
        "non_covid_files      = [os.path.join(non_covid_files_path, x) for x in os.listdir(non_covid_files_path)]\n",
        "non_covid_images    =  [cv2.imread(x) for x in random.sample(non_covid_files, 10)]\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "columns = 5\n",
        "for i, image in enumerate(non_covid_images):\n",
        "    plt.subplot(len(non_covid_images) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlzir75dOT3Q"
      },
      "source": [
        "class CovidCTDataset(Dataset):\n",
        "    def __init__(self, root_dir, classes, covid_files, non_covid_files, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = classes\n",
        "        self.files_path = [non_covid_files, covid_files]\n",
        "        self.image_list = []\n",
        "\n",
        "        # read the files from data split text files\n",
        "        covid_files = read_txt(covid_files)\n",
        "        non_covid_files = read_txt(non_covid_files)\n",
        "\n",
        "        # combine the positive and negative files into a cummulative files list\n",
        "        for cls_index in range(len(self.classes)):\n",
        "            \n",
        "            class_files = [[os.path.join(self.root_dir, self.classes[cls_index], x), cls_index] \\\n",
        "                            for x in read_txt(self.files_path[cls_index])]\n",
        "            self.image_list += class_files\n",
        "                \n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_list[idx][0]\n",
        "        \n",
        "        # Read the image\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = int(self.image_list[idx][1])\n",
        "\n",
        "        data = {'img':   image,\n",
        "                'label': label,\n",
        "                'paths' : path}\n",
        "\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWR1Y1wRjAZ"
      },
      "source": [
        "def read_txt(txt_path):\n",
        "    with open(txt_path) as f:\n",
        "        lines = f.readlines()\n",
        "    txt_data = [line.strip() for line in lines]\n",
        "    return txt_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n430HK1hRmlp"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n",
        "train_transformer = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "val_transformer = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnFcgP5pSCzh"
      },
      "source": [
        "batchsize = 8\n",
        "\n",
        "trainset = CovidCTDataset(root_dir='Images-processed/',\n",
        "                          classes = ['CT_NonCOVID', 'CT_COVID'],\n",
        "                          covid_files='Data-split/COVID/trainCT_COVID.txt',\n",
        "                          non_covid_files='Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
        "                          transform= train_transformer)\n",
        "valset = CovidCTDataset(root_dir='Images-processed/',\n",
        "                          classes = ['CT_NonCOVID', 'CT_COVID'],\n",
        "                          covid_files='Data-split/COVID/valCT_COVID.txt',\n",
        "                          non_covid_files = 'Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
        "                          transform= val_transformer)\n",
        "testset = CovidCTDataset(root_dir='Images-processed/',\n",
        "                          classes = ['CT_NonCOVID', 'CT_COVID'],\n",
        "                          covid_files='Data-split/COVID/testCT_COVID.txt',\n",
        "                          non_covid_files='Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
        "                          transform= val_transformer)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
        "val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
        "test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziQG_2eVaVyF"
      },
      "source": [
        "model = vgg19_bn(pretrained=True)\n",
        "model.classifier[6] = nn.Linear(4096, 2)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Gd1kRyjLvr"
      },
      "source": [
        "learning_rate = 0.01\n",
        "optimizer     = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfGxXzdrkPSS"
      },
      "source": [
        "def compute_metrics(model, test_loader, plot_roc_curve = False):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    score_list   = torch.Tensor([]).to(device)\n",
        "    pred_list    = torch.Tensor([]).to(device).long()\n",
        "    target_list  = torch.Tensor([]).to(device).long()\n",
        "    path_list    = []\n",
        "\n",
        "    \n",
        "    for iter_num, data in enumerate(test_loader):\n",
        "        \n",
        "        # Convert image data into single channel data\n",
        "        image, target = data['img'].to(device), data['label'].to(device)\n",
        "        paths = data['paths']\n",
        "        path_list.extend(paths)\n",
        "        \n",
        "        # Compute the loss\n",
        "        with torch.no_grad():\n",
        "            output = model(image)\n",
        "        \n",
        "        # Log loss\n",
        "        val_loss += criterion(output, target.long()).item()\n",
        "\n",
        "        \n",
        "        # Calculate the number of correctly classified examples\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        val_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
        "        \n",
        "        # Bookkeeping \n",
        "        score_list   = torch.cat([score_list, nn.Softmax(dim = 1)(output)[:,1].squeeze()])\n",
        "        pred_list    = torch.cat([pred_list, pred.squeeze()])\n",
        "        target_list  = torch.cat([target_list, target.squeeze()])\n",
        "        \n",
        "    \n",
        "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
        "                                                  target_names = ['CT_NonCOVID', 'CT_COVID'],\n",
        "                                                  output_dict= True)\n",
        "    \n",
        "    \n",
        "    # sensitivity is the recall of the positive class\n",
        "    sensitivity = classification_metrics['CT_COVID']['recall']\n",
        "    \n",
        "    # specificity is the recall of the negative class \n",
        "    specificity = classification_metrics['CT_NonCOVID']['recall']\n",
        "    \n",
        "    # accuracy\n",
        "    accuracy = classification_metrics['accuracy']\n",
        "    \n",
        "    # confusion matrix\n",
        "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
        "    \n",
        "    # roc score\n",
        "    roc_score = roc_auc_score(target_list.tolist(), score_list.tolist())\n",
        "    \n",
        "    # plot the roc curve\n",
        "    if plot_roc_curve:\n",
        "        fpr, tpr, _ = roc_curve(target_list.tolist(), score_list.tolist())\n",
        "        plt.plot(fpr, tpr, label = \"Area under ROC = {:.4f}\".format(roc_score))\n",
        "        plt.legend(loc = 'best')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.show()\n",
        "        \n",
        "    \n",
        "    # put together values\n",
        "    metrics_dict = {\"Accuracy\": accuracy,\n",
        "                    \"Sensitivity\": sensitivity,\n",
        "                    \"Specificity\": specificity,\n",
        "                    \"Roc_score\"  : roc_score, \n",
        "                    \"Confusion Matrix\": conf_matrix,\n",
        "                    \"Validation Loss\": val_loss / len(test_loader),\n",
        "                    \"score_list\":  score_list.tolist(),\n",
        "                    \"pred_list\": pred_list.tolist(),\n",
        "                    \"target_list\": target_list.tolist(),\n",
        "                    \"paths\": path_list}\n",
        "    \n",
        "    \n",
        "    return metrics_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFo-DY6dkZnJ"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "class EarlyStopping(object):\n",
        "    def __init__(self, patience = 8):\n",
        "        super(EarlyStopping, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.previous_loss = int(1e8)\n",
        "        self.previous_accuracy = 0\n",
        "        self.init = False\n",
        "        self.accuracy_decrease_iters = 0\n",
        "        self.loss_increase_iters = 0\n",
        "        self.best_running_accuracy = 0\n",
        "        self.best_running_loss = int(1e7)\n",
        "    \n",
        "    def add_data(self, model, loss, accuracy):\n",
        "        \n",
        "        # compute moving average\n",
        "        if not self.init:\n",
        "            running_loss = loss\n",
        "            running_accuracy = accuracy \n",
        "            self.init = True\n",
        "        \n",
        "        else:\n",
        "            running_loss = 0.2 * loss + 0.8 * self.previous_loss\n",
        "            running_accuracy = 0.2 * accuracy + 0.8 * self.previous_accuracy\n",
        "        \n",
        "        # check if running accuracy has improved beyond the best running accuracy recorded so far\n",
        "        if running_accuracy < self.best_running_accuracy:\n",
        "            self.accuracy_decrease_iters += 1\n",
        "        else:\n",
        "            self.best_running_accuracy = running_accuracy\n",
        "            self.accuracy_decrease_iters = 0\n",
        "        \n",
        "        # check if the running loss has decreased from the best running loss recorded so far\n",
        "        if running_loss > self.best_running_loss:\n",
        "            self.loss_increase_iters += 1\n",
        "        else:\n",
        "            self.best_running_loss = running_loss\n",
        "            self.loss_increase_iters = 0\n",
        "        \n",
        "        # log the current accuracy and loss\n",
        "        self.previous_accuracy = running_accuracy\n",
        "        self.previous_loss = running_loss        \n",
        "        \n",
        "    \n",
        "    def stop(self):\n",
        "        \n",
        "        # compute thresholds\n",
        "        accuracy_threshold = self.accuracy_decrease_iters > self.patience\n",
        "        loss_threshold = self.loss_increase_iters > self.patience\n",
        "        \n",
        "        \n",
        "        # return codes corresponding to exhuaustion of patience for either accuracy or loss \n",
        "        # or both of them\n",
        "        if accuracy_threshold and loss_threshold:\n",
        "            return 1\n",
        "        \n",
        "        if accuracy_threshold:\n",
        "            return 2\n",
        "        \n",
        "        if loss_threshold:\n",
        "            return 3\n",
        "        \n",
        "        \n",
        "        return 0\n",
        "    \n",
        "    def reset(self):\n",
        "        # reset\n",
        "        self.accuracy_decrease_iters = 0\n",
        "        self.loss_increase_iters = 0\n",
        "    \n",
        "early_stopper = EarlyStopping(patience = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9g7mjgPkeF5"
      },
      "source": [
        "best_model = model\n",
        "best_val_score = 0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(60):\n",
        "\n",
        "    model.train()    \n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    \n",
        "    for iter_num, data in enumerate(train_loader):\n",
        "        image, target = data['img'].to(device), data['label'].to(device)     \n",
        "\n",
        "        # Compute the loss\n",
        "        output = model(image)\n",
        "        loss = criterion(output, target.long()) / 8\n",
        "        \n",
        "        # Log loss\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform gradient udpate\n",
        "        if iter_num % 8 == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "\n",
        "        # Calculate the number of correctly classified examples\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
        "        \n",
        "    \n",
        "    # Compute and print the performance metrics\n",
        "    metrics_dict = compute_metrics(model, val_loader)\n",
        "    print('------------------ Epoch {} Iteration {}--------------------------------------'.format(epoch,\n",
        "                                                                                                 iter_num))\n",
        "    print(\"Accuracy \\t {:.3f}\".format(metrics_dict['Accuracy']))\n",
        "    print(\"Sensitivity \\t {:.3f}\".format(metrics_dict['Sensitivity']))\n",
        "    print(\"Specificity \\t {:.3f}\".format(metrics_dict['Specificity']))\n",
        "    print(\"Area Under ROC \\t {:.3f}\".format(metrics_dict['Roc_score']))\n",
        "    print(\"Val Loss \\t {}\".format(metrics_dict[\"Validation Loss\"]))\n",
        "    print(\"------------------------------------------------------------------------------\")\n",
        "    \n",
        "    # Save the model with best validation accuracy\n",
        "    if metrics_dict['Accuracy'] > best_val_score:\n",
        "        torch.save(model, \"best_model.pkl\")\n",
        "        best_val_score = metrics_dict['Accuracy']\n",
        "    \n",
        "    \n",
        "    # print the metrics for training data for the epoch\n",
        "    print('\\nTraining Performance Epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        epoch, train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
        "        100.0 * train_correct / len(train_loader.dataset)))\n",
        "    \n",
        "    # log the accuracy and losses in tensorboard\n",
        "    writer.add_scalars( \"Losses\", {'Train loss': train_loss / len(train_loader), 'Validation_loss': metrics_dict[\"Validation Loss\"]},\n",
        "                                   epoch)\n",
        "    writer.add_scalars( \"Accuracies\", {\"Train Accuracy\": 100.0 * train_correct / len(train_loader.dataset),\n",
        "                                       \"Valid Accuracy\": 100.0 * metrics_dict[\"Accuracy\"]}, epoch)\n",
        "\n",
        "    # Add data to the EarlyStopper object\n",
        "    early_stopper.add_data(model, metrics_dict['Validation Loss'], metrics_dict['Accuracy'])\n",
        "    \n",
        "    # If both accuracy and loss are not improving, stop the training\n",
        "    if early_stopper.stop() == 1:\n",
        "        break\n",
        "    \n",
        "    # if only loss is not improving, lower the learning rate\n",
        "    if early_stopper.stop() == 3:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            learning_rate *= 0.1\n",
        "            param_group['lr'] = learning_rate\n",
        "            print('Updating the learning rate to {}'.format(learning_rate))\n",
        "            early_stopper.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6dadp-WmthT"
      },
      "source": [
        "# model = torch.load(\"best_model.pkl\")\n",
        "model = torch.load(\"/content/COVID-CT/best_model.pkl\" )\n",
        "\n",
        "metrics_dict = compute_metrics(model, test_loader, plot_roc_curve = True)\n",
        "print('------------------- Test Performance --------------------------------------')\n",
        "print(\"Accuracy \\t {:.3f}\".format(metrics_dict['Accuracy']))\n",
        "print(\"Sensitivity \\t {:.3f}\".format(metrics_dict['Sensitivity']))\n",
        "print(\"Specificity \\t {:.3f}\".format(metrics_dict['Specificity']))\n",
        "print(\"Area Under ROC \\t {:.3f}\".format(metrics_dict['Roc_score']))\n",
        "print(\"------------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C5CY7GuoBGa"
      },
      "source": [
        "conf_matrix = metrics_dict[\"Confusion Matrix\"]\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, ax = ax, cmap = 'Blues'); #annot=True to annotate cells\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['CoViD', 'NonCoViD']); ax.yaxis.set_ticklabels(['CoViD', 'NonCoViD']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8JmcB4frbHL"
      },
      "source": [
        "targets = np.array(metrics_dict['target_list'])\n",
        "preds   = np.array(metrics_dict['pred_list'])\n",
        "scores  = np.array(metrics_dict['score_list'])\n",
        "\n",
        "\n",
        "misclassified_indexes = np.nonzero(targets != preds)\n",
        "misclassified_scores = scores[misclassified_indexes[0]]\n",
        "\n",
        "# plot the historgram of misclassified scores\n",
        "plt.hist(misclassified_scores)\n",
        "plt.xlabel(\"scores\")\n",
        "plt.ylabel(\"No. of examples\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "solJXk0lrkSL"
      },
      "source": [
        "!git clone https://github.com/jacobgil/pytorch-grad-cam\n",
        "!mv pytorch-grad-cam gradcam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRVHVTOxrxkr"
      },
      "source": [
        "from gradcam.gradcam import *\n",
        "\n",
        "def do_grad_cam(path):\n",
        "\n",
        "     \n",
        "    grad_cam = GradCam(model=model, feature_module=model.features, \\\n",
        "                           target_layer_names=[\"35\"], use_cuda=True)\n",
        "\n",
        "    orig_im = cv2.imread(path)\n",
        "    img = Image.fromarray(orig_im)\n",
        "    inp = val_transformer(img).unsqueeze(0)\n",
        "\n",
        "    mask = grad_cam(inp, None)\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "    \n",
        "    cam = heatmap + np.float32(cv2.resize(orig_im, (224,224))/255.)\n",
        "    cam = cam / np.max(cam)\n",
        "    \n",
        "    cam = cam[:,:,::-1] \n",
        "    \n",
        "    return cam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI_6dfG9r09b"
      },
      "source": [
        "true_positives = np.logical_and(preds == 1, targets == 1)\n",
        "true_positives = np.logical_and(true_positives, scores > 0.9)\n",
        "true_positives_indices = np.nonzero(true_positives)\n",
        "true_positives_paths = [metrics_dict['paths'][i] for i in true_positives_indices[0]]\n",
        "\n",
        "\n",
        "true_positive_images    =  [do_grad_cam(x) for x in random.sample(true_positives_paths, 10)]\n",
        "\n",
        "plt.figure(figsize=(30,15))\n",
        "columns = 5\n",
        "for i, image in enumerate(true_positive_images):\n",
        "    plt.subplot(len(true_positive_images) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8TMyd60wSuU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}